{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edeceebf-5caf-4875-9e85-c46bb4f8509c",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cb1531-693d-40c2-b86d-88f1fb042414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://271e3af91e45:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe1870baa50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reset kernel when start this notebook\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14db674-e957-4ac4-920d-edfa623ae958",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "* As Spark Dataframes operations are lazy, we need to use show() to trigger the computation and see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f51b6c-f47b-4514-bef4-030115890e11",
   "metadata": {},
   "source": [
    "Data dictionary of this dataset can be found in the following link:\n",
    "https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffba63c1-f2e9-47bb-9596-05ea2166c3c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdf = spark.read.format(\"parquet\").option(\"inferSchema\", \"true\").option(\"timestampFormat\",\"yyyy-MM-dd HH:mm:ss\").option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").load(\"dataset/yellow_tripdata_2017-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb1126c-a338-49d3-aae5-aac94c179f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: integer (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the type of data of each column\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "190b1825-7976-4a94-860f-489d403f856f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9710820"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the number of records\n",
    "sdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5323733-dead-4d08-ae6d-a24486129f32",
   "metadata": {},
   "source": [
    "9'710.820 - 4'856.845"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe791754-a293-49b9-8621-877d1ced429e",
   "metadata": {},
   "source": [
    "## Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392d4cf6-4399-4391-b4d2-397b620ceb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, when, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b37e72-4365-4630-908f-69ce517ab701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       0|                   0|                    0|              0|            0|         0|                 0|           0|           0|           0|          0|    0|      0|         0|           0|                    0|           0|             9710820|    9710820|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of expressions that count null values for each column\n",
    "null_counts = [sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in sdf.columns]\n",
    "\n",
    "# Apply the expressions to the DataFrame and display the result\n",
    "# The '*' is used to unpack the list and pass each expression as separete arg\n",
    "# The agg funciton is to apply the expressions to the dataframe 'sdf'\n",
    "sdf.agg(*null_counts).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b65e126-fc52-496f-b166-b81c63466c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 'congestion_surcharge' and 'airport_fee' columns are null, let's remove them\n",
    "sdf = sdf.drop(*[\"congestion_surcharge\",\"airport_fee\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c48e9bb-48c3-4e60-ad0c-0c4bf8de3714",
   "metadata": {},
   "source": [
    "## Take a sample from the dataset\n",
    "Select a set of records randomly to limit the size of the dataset, thus executing operations easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66aaf2bf-31c4-43ca-a79b-22986bd352c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the sample '4856845'\n"
     ]
    }
   ],
   "source": [
    "sdf = sdf.sample(withReplacement=False, fraction=0.5, seed=15)\n",
    "new_size = sdf.count()\n",
    "print(f\"Size of the sample '{new_size}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124a1f7-a4f7-480a-bcd5-968033957079",
   "metadata": {},
   "source": [
    "# Estudio #1 -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c56b6bd-9003-4049-be7a-32e05ce83899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7ed995-694d-47ac-b9b9-ff6c5888f896",
   "metadata": {},
   "source": [
    "# Estudio #2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4dec12-308b-4b32-9132-d3c0c5570fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc267d1b-743a-40e9-a232-6521e28e4b27",
   "metadata": {},
   "source": [
    "# Estudio #3 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d609925-d888-40d0-a263-c482afb8c6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c024467-e362-44a2-8412-d14bad3fe653",
   "metadata": {},
   "source": [
    "# Estudio #4 - Taxi Velocity average in each hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab70857-2a2f-4797-bb03-38270313823f",
   "metadata": {},
   "source": [
    "### Dataframe operations - Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb6847b-5036-4037-b408-4a98e3f15907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operations reduced\n",
    "from pyspark.sql.functions import hour, udf, avg\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "#convert to seconds manually through User defined functions (UDF)\n",
    "def interval_to_seconds(interval):\n",
    "    total_seconds = interval.total_seconds()\n",
    "    return int(total_seconds)\n",
    "\n",
    "interval_to_seconds_udf = udf(interval_to_seconds, IntegerType())\n",
    "\n",
    "# START THE TIMER\n",
    "sdf = sdf.withColumn(\"duration\", col(\"tpep_dropoff_datetime\")-col(\"tpep_pickup_datetime\"))\n",
    "sdf = sdf.withColumn(\"duration\", (interval_to_seconds_udf(col(\"duration\")) / 3600))\n",
    "sdf = sdf.filter(col(\"duration\") > 0)\n",
    "sdf = sdf.withColumn(\"velocity\",col(\"trip_distance\")/col(\"duration\"))\n",
    "sdf = sdf.withColumn(\"hour_pickup\", hour(col(\"tpep_pickup_datetime\")))\n",
    "sdf = sdf.withColumn(\"hour_dropoff\", hour(col(\"tpep_dropoff_datetime\")))\n",
    "result_df = sdf.groupBy(\"hour_pickup\").agg(avg(\"velocity\").alias(\"VelocityAvg\")).orderBy(\"hour_pickup\")\n",
    "#STOP TIMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f72fdf-0156-4f33-8539-a4be3da889ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's calculate the difference of time between the pick-up and the drop-off\n",
    "sdf = sdf.withColumn(\"duration\", col(\"tpep_dropoff_datetime\")-col(\"tpep_pickup_datetime\"))\n",
    "sdf.select(\"duration\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751e7103-6b65-44b2-b9d1-5470676b2725",
   "metadata": {},
   "source": [
    "### Check duration of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70838589-85c0-4950-bde3-763805f2d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "\n",
    "#convert to seconds manually through User defined functions (UDF)\n",
    "def interval_to_seconds(interval):\n",
    "    total_seconds = interval.total_seconds()\n",
    "    return int(total_seconds)\n",
    "\n",
    "interval_to_seconds_udf = udf(interval_to_seconds, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff39711-5420-4e5b-857c-5e641ad652c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the UDF to extract seconds and store in a new column\n",
    "sdf = sdf.withColumn(\"duration\", interval_to_seconds_udf(col(\"duration\")))\n",
    "\n",
    "# Show the DataFrame with the extracted seconds\n",
    "sdf.select(\"duration\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414615b9-da6a-4f7e-8615-1c8b094c4b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's check for some anomalities in this column\n",
    "sdf.filter(col(\"duration\") < 0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab7a43-5067-4009-af25-34471244d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.filter(col(\"duration\") == 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e4518-14c4-427d-8f02-486bb753843e",
   "metadata": {},
   "source": [
    "All the above records shows that all the trips where finished at the same time when started.\n",
    "\n",
    "Because of all these records, we proceed to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d695b99-fc1d-4d1a-8ffc-2e07185a255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf.filter(col(\"duration\") > 0)\n",
    "size_after_reduction = sdf.count()\n",
    "print(f\"Size of the sample '{size_after_reduction}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0810b6-6b7f-4d1a-b25b-9339fadb671f",
   "metadata": {},
   "source": [
    "### Calculate Velocity of each trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83effc8-8f80-4f1d-8a24-61ba4a64da98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#As the duration column is in seconds, we have to divide the value between 3600 to the value in hour units.\n",
    "sdf = sdf.withColumn(\"velocity\",col(\"trip_distance\")/(col(\"duration\")/3600))\n",
    "sdf.select(\"velocity\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87d01f-11fe-46b2-bd1b-5392d8432b65",
   "metadata": {},
   "source": [
    "*The units of these values are miles per hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa40935-daae-416c-9257-5c1cbde91b72",
   "metadata": {},
   "source": [
    "### Calculate avg per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974b01d-4af3-46a4-847d-c0e53892641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcd1ba-e61e-4736-b2ee-71138bb0efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf.withColumn(\"hour_pickup\", hour(col(\"tpep_pickup_datetime\")))\n",
    "sdf = sdf.withColumn(\"hour_dropoff\", hour(col(\"tpep_dropoff_datetime\")))\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa5b6e-2bb0-4d8a-b237-7a602d224721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b778bae-b6ae-4a74-8dac-25754cba150d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df = sdf.groupBy(\"hour_pickup\").agg(avg(\"velocity\").alias(\"VelocityAvg\")).orderBy(\"hour_pickup\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "result_df.show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e055078-c20f-477f-859c-44a358f14b59",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2840f2-32b2-4cf7-b395-0c806b90901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990cbd2-9786-4eca-81c9-c0f208ba6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "max = result_df.agg(max(\"VelocityAvg\")).collect()[0][0]\n",
    "min = result_df.agg(min(\"VelocityAvg\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17636826-3ce0-4905-989f-92ec8010b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_value = (max/min)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e2115-8788-4610-bf53-dc1a60aafd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom color mapping based on numeric values\n",
    "def custom_color_palette(x):\n",
    "    if x <= center_value:\n",
    "        return \"lightblue\"  # Light blue for values less than 50\n",
    "    else:\n",
    "        return \"lightred\"  # Light green for values between 50 and 100\n",
    "\n",
    "custom_color_palette_udf = udf(custom_color_palette, StringType())\n",
    "\n",
    "result_df = result_df.withColumn(\"Color\", custom_color_palette_udf(col(\"VelocityAvg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406d270-4b8a-45b2-a3f9-41f6ce14c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "result_df_p = result_df.toPandas()\n",
    "barplot = sns.barplot(data=result_df_p, x=\"hour_pickup\", y=\"VelocityAvg\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Average velocity\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b718c7-70f0-4233-ac2d-b35dbb456cc7",
   "metadata": {},
   "source": [
    "# Analisis de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f1fdc-7126-4adf-9ff1-b69b7d4ae9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654315e-a6a9-4e3c-9422-a1c5e2e573a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c0855-0dcf-450c-9fb3-024d3348fed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
